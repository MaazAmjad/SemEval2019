{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lxml.etree import iterparse\n",
    "import xml\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import pickle\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import re\n",
    "from lxml import etree\n",
    "import html\n",
    "\n",
    "from utils import fixedTestSplit, cleanQuotations, cleanText, read_glove, customTokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fixup(x):\n",
    "    '''\n",
    "    fix some HTML codes and white spaces\n",
    "    '''\n",
    "    re1 = re.compile(r'  +')\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class GroundTruthHandler(xml.sax.ContentHandler):\n",
    "    def __init__(self, gt, source):\n",
    "        xml.sax.ContentHandler.__init__(self)\n",
    "        self.gt = gt\n",
    "        self.source = source\n",
    "\n",
    "    def startElement(self, name, attrs):\n",
    "        if name == \"article\":\n",
    "            articleId = attrs.getValue(\"id\")\n",
    "            url = attrs.getValue(\"url\")\n",
    "            url = '/'.join(url.split('/')[:3])\n",
    "            self.source.append(url)\n",
    "\n",
    "            self.gt.append(attrs.getValue(\"hyperpartisan\"))\n",
    "            \n",
    "def readFiles(textFile, labelFile):\n",
    "    X,y = [], []\n",
    "    sources = []\n",
    "    \n",
    "    with open(labelFile) as labelFile:\n",
    "        xml.sax.parse(labelFile, GroundTruthHandler(y, sources))\n",
    "       \n",
    "    for event, elem in iterparse(textFile):\n",
    "        if elem.tag == \"article\":\n",
    "            title = elem.attrib['title']\n",
    "            text = \"\".join(elem.itertext())\n",
    "            title = cleanQuotations(title)\n",
    "            text = cleanQuotations(text)\n",
    "            text = cleanText(fixup(text))\n",
    "            text = ' '.join(text.split()[:1000])\n",
    "            X.append(title + \". \" + text)\n",
    "            elem.clear()\n",
    "            \n",
    "    return np.asarray(X), np.asarray(y), np.asarray(sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read in labels and texts\n",
    "dataPath = 'C:/Users/sharo/Documents/SemEval2019/data/'\n",
    "trainFiles = [dataPath + 'articles-training-bypublisher.xml', dataPath + 'articles-validation-bypublisher.xml']\n",
    "textFile = dataPath + 'articles-training-byarticle.xml'\n",
    "labelFile = dataPath + \"ground-truth-training-byarticle.xml\"\n",
    "texts, labels, sources = readFiles(textFile, labelFile)\n",
    "id1, id2 = fixedTestSplit(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gloveVectorize(glove, text):\n",
    "    dim = len(glove[\"the\"])\n",
    "    X = np.zeros( (len(text), dim) )\n",
    "    for text_id, t in enumerate(text):\n",
    "        tmp = np.zeros((1,300))\n",
    "        words = customTokenize(t, True)\n",
    "        words = [w for w in words if w in glove.keys()]\n",
    "        for word in words:\n",
    "            tmp[:] += glove[word]\n",
    "        X[text_id, :] = tmp/len(words)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove = read_glove(\"C:/Users/sharo/Documents/SemEval2019/pretrained_wv/\", 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_texts = gloveVectorize(glove, texts)\n",
    "train_x = glove_texts[id1]\n",
    "test_x = glove_texts[id2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KernelSVM] C=0.500000 | acc=0.764067\n",
      "[KernelSVM] C=0.600000 | acc=0.776472\n",
      "[KernelSVM] C=0.700000 | acc=0.776567\n",
      "[KernelSVM] C=0.900000 | acc=0.779793\n",
      "[KernelSVM] C=1.000000 | acc=0.773442\n",
      "[KernelSVM] C=1.100000 | acc=0.776472\n",
      "[KernelSVM] C=1.200000 | acc=0.776472\n",
      "[KernelSVM] C=5.000000 | acc=0.751176\n",
      "[KernelSVM] C=10.000000 | acc=0.751075\n"
     ]
    }
   ],
   "source": [
    "C = [0.5, 0.6, 0.7, 0.9,1,1.1, 1.2, 5,10]\n",
    "for c in C:\n",
    "    kernel_svm = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(C=c, gamma=\"auto\", max_iter = 1000))\n",
    "    ])\n",
    "    print(\"[KernelSVM] C=%f | acc=%f\" %(c,np.mean(cross_val_score(kernel_svm, train_x, labels[id1], cv=10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogisticR] C=0.050000 | acc=0.645760\n",
      "[LogisticR] C=0.100000 | acc=0.693038\n",
      "[LogisticR] C=0.500000 | acc=0.748714\n",
      "[LogisticR] C=0.800000 | acc=0.757805\n",
      "[LogisticR] C=0.900000 | acc=0.764061\n",
      "[LogisticR] C=1.000000 | acc=0.764061\n",
      "[LogisticR] C=2.000000 | acc=0.751750\n",
      "[LogisticR] C=3.000000 | acc=0.748525\n",
      "[LogisticR] C=5.000000 | acc=0.745400\n"
     ]
    }
   ],
   "source": [
    "C = [0.05, 0.1, 0.5, 0.8, 0.9, 1, 2, 3, 5]\n",
    "for c in C:\n",
    "    lr = LogisticRegression(solver = 'lbfgs', C = c, max_iter=1000)\n",
    "    print(\"[LogisticR] C=%f | acc=%f\" %(c,np.mean(cross_val_score(lr, train_x, labels[id1], cv=10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9130434782608695\n",
      "Test accuracy:  0.7956656346749226\n",
      "Test precision:  0.7676767676767676\n",
      "Test recall:  0.6386554621848739\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[181,  23],\n",
       "       [ 43,  76]], dtype=int64)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svc\", SVC(C=0.9, gamma=\"auto\", max_iter = 5000))\n",
    "        ])\n",
    "\n",
    "model.fit(train_x, labels[id1])\n",
    "trn_pred = model.predict(train_x)\n",
    "tst_pred = model.predict(test_x)\n",
    "print('Train accuracy: ', accuracy_score(labels[id1], trn_pred))\n",
    "print('Test accuracy: ', accuracy_score(labels[id2], tst_pred))\n",
    "print('Test precision: ', precision_score(labels[id2], tst_pred, pos_label='true'))\n",
    "print('Test recall: ', recall_score(labels[id2], tst_pred, pos_label='true'))\n",
    "confusion_matrix(labels[id2], tst_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"glove_pred_svm\", tst_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8043478260869565\n",
      "Test accuracy:  0.7244582043343654\n",
      "Test precision:  0.6442307692307693\n",
      "Test recall:  0.5630252100840336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[167,  37],\n",
       "       [ 52,  67]], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(solver = 'lbfgs', C = 1, max_iter=1000)\n",
    "model.fit(train_x, labels[id1])\n",
    "trn_pred = model.predict(train_x)\n",
    "tst_pred = model.predict(test_x)\n",
    "print('Train accuracy: ', accuracy_score(labels[id1], trn_pred))\n",
    "print('Test accuracy: ', accuracy_score(labels[id2], tst_pred))\n",
    "print('Test precision: ', precision_score(labels[id2], tst_pred, pos_label='true'))\n",
    "print('Test recall: ', recall_score(labels[id2], tst_pred, pos_label='true'))\n",
    "confusion_matrix(labels[id2], tst_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit the model to all samples\n",
    "model.fit(glove_texts, labels)\n",
    "# save the model\n",
    "pickle.dump(model, open('./svm_glove_original.sav', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\gensim\\utils.py:1212: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "word_vectors = KeyedVectors.load_word2vec_format(\"C:/Users/sharo/Documents/SemEval2019/pretrained_wv/\" + \"GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wvVectorize(wv, text):\n",
    "    dim = len(word_vectors.word_vec('the') )\n",
    "    X = np.zeros( (len(text), dim) )\n",
    "    for text_id, t in enumerate(text):\n",
    "        tmp = np.zeros((1,300))\n",
    "        words = customTokenize(t)\n",
    "        words = [w for w in words if w in word_vectors.vocab]\n",
    "        for word in words:\n",
    "            tmp[:] += word_vectors.word_vec(word)\n",
    "        X[text_id, :] = tmp/len(words)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wv_texts = wvVectorize(word_vectors, texts)\n",
    "train_x = wv_texts[id1]\n",
    "test_x = wv_texts[id2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KernelSVM] C=0.100000 | acc=0.652212\n",
      "[KernelSVM] C=0.300000 | acc=0.773353\n",
      "[KernelSVM] C=0.500000 | acc=0.779698\n",
      "[KernelSVM] C=0.700000 | acc=0.776283\n",
      "[KernelSVM] C=1.000000 | acc=0.776182\n",
      "[KernelSVM] C=5.000000 | acc=0.766990\n"
     ]
    }
   ],
   "source": [
    "C = [0.1, 0.3, 0.5, 0.7, 1, 5]\n",
    "for c in C:\n",
    "    kernel_svm = Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"svc\", SVC(C=c, gamma=\"auto\", max_iter = 1000))\n",
    "    ])\n",
    "    print(\"[KernelSVM] C=%f | acc=%f\" %(c,np.mean(cross_val_score(kernel_svm, train_x, labels[id1], cv=10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LogisticR] C=0.050000 | acc=0.630425\n",
      "[LogisticR] C=0.100000 | acc=0.630425\n",
      "[LogisticR] C=0.500000 | acc=0.689913\n",
      "[LogisticR] C=1.000000 | acc=0.723909\n",
      "[LogisticR] C=5.000000 | acc=0.764156\n",
      "[LogisticR] C=10.000000 | acc=0.760930\n"
     ]
    }
   ],
   "source": [
    "C = [0.05, 0.1, 0.5, 1, 5, 10]\n",
    "for c in C:\n",
    "    lr = LogisticRegression(solver = 'lbfgs', C = c, max_iter=1000)\n",
    "    print(\"[LogisticR] C=%f | acc=%f\" %(c,np.mean(cross_val_score(lr, train_x, labels[id1], cv=10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8633540372670807\n",
      "Test accuracy:  0.7585139318885449\n",
      "Test precision:  0.7204301075268817\n",
      "Test recall:  0.5630252100840336\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[178,  26],\n",
       "       [ 52,  67]], dtype=int64)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Pipeline([\n",
    "            (\"scaler\", StandardScaler()),\n",
    "            (\"svc\", SVC(C=0.5, gamma=\"auto\", max_iter = 5000))\n",
    "        ])\n",
    "\n",
    "model.fit(train_x, labels[id1])\n",
    "trn_pred = model.predict(train_x)\n",
    "tst_pred = model.predict(test_x)\n",
    "print('Train accuracy: ', accuracy_score(labels[id1], trn_pred))\n",
    "print('Test accuracy: ', accuracy_score(labels[id2], tst_pred))\n",
    "print('Test precision: ', precision_score(labels[id2], tst_pred, pos_label='true'))\n",
    "print('Test recall: ', recall_score(labels[id2], tst_pred, pos_label='true'))\n",
    "confusion_matrix(labels[id2], tst_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fnIdx = np.intersect1d(np.where(gt == 'true')[0], (np.where(pred == 'false')[0]))\n",
    "#fpIdx = np.intersect1d(np.where(gt == 'false')[0], (np.where(pred == 'true')[0]))\n",
    "\n",
    "\n",
    "corr = [i for i in range(len(labels[id2])) if labels[id2][i] == tst_pred[i]]\n",
    "wrong = texts[id2[np.concatenate((fnIdx, fpIdx))]]\n",
    "correct = texts[id2[corr]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
